def permutation_rfecv(X, y, model_type="LGBM", scoring="roc_auc", step=1, min_features_to_select=5, cv=5, sample_size=None):
    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt
    from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score
    from sklearn.inspection import permutation_importance
    from sklearn.preprocessing import StandardScaler
    from sklearn.metrics import roc_auc_score

    model = get_model_by_type(model_type)
    X = X.copy()
    y = y.copy()
    
    if sample_size is not None and sample_size < len(X):
        X = X.sample(n=sample_size, random_state=42)
        y = y.loc[X.index]

    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)

    current_features = list(X_scaled.columns)
    all_removed = []
    results = []
    iteration = 0

    while len(current_features) > min_features_to_select:
        iteration += 1
        model.fit(X_scaled[current_features], y)

        # Permutation importance hesapla
        result = permutation_importance(model, X_scaled[current_features], y, scoring=scoring,
                                        n_repeats=5, random_state=42)
        perm_df = pd.DataFrame({
            "feature": current_features,
            "importance": result.importances_mean
        }).sort_values(by="importance")

        to_remove = perm_df["feature"].iloc[:step].tolist()
        all_removed.extend(to_remove)

        # AUC hesapla
        try:
            cv_scores = cross_val_score(model, X_scaled[current_features], y,
                                         cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),
                                         scoring=scoring)
            mean_auc = round(np.mean(cv_scores), 5)
            std_auc = round(np.std(cv_scores), 5)
        except Exception as e:
            print(f"[{iteration}] CV skipped: {e}")
            mean_auc = np.nan
            std_auc = np.nan

        results.append({
            "iteration": iteration,
            "n_features": len(current_features),
            "mean_auc": mean_auc,
            "std_auc": std_auc,
            "selected_features": current_features.copy(),
            "removed_features": to_remove,
            "cumulative_removed_features": all_removed.copy()
        })

        current_features = [f for f in current_features if f not in to_remove]

    results_df = pd.DataFrame(results)
    best_row = results_df.loc[results_df["mean_auc"].idxmax()]
    best_features = best_row["selected_features"]

    # Final Train/Test AUC hesapla
    X_train, X_test, y_train, y_test = train_test_split(X[best_features], y, test_size=0.2, random_state=42, stratify=y)
    model = get_model_by_type(model_type)
    model.fit(X_train, y_train)
    train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])
    test_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])

    # Grafik
    plt.figure(figsize=(8, 5))
    plt.plot(results_df["n_features"], results_df["mean_auc"], marker="o", label="CV AUC")
    plt.fill_between(results_df["n_features"],
                     results_df["mean_auc"] - results_df["std_auc"],
                     results_df["mean_auc"] + results_df["std_auc"],
                     alpha=0.2, label="Â±1 STD")
    plt.axvline(len(best_features), linestyle="--", color="red", label=f"Best: {len(best_features)}")
    plt.xlabel("Number of Features")
    plt.ylabel("Mean ROC AUC")
    plt.title(f"Permutation RFECV Performance ({model_type})")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

    return {
        "results_df": results_df,
        "best_features": best_features,
        "train_auc": train_auc,
        "test_auc": test_auc
    }